{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "num_nodes = 100\n",
    "\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "train_mask[:20] = True  \n",
    "\n",
    "x = torch.randn(num_nodes, 16)  \n",
    "y = torch.randint(0, 3, (num_nodes,))  \n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]], dtype=torch.long)  \n",
    "\n",
    "data = Data(x=x, edge_index=edge_index, y=y, train_mask=train_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 1.1416312456130981\n",
      "Epoch 2: Loss = 0.9766517877578735\n",
      "Epoch 3: Loss = 0.8443997502326965\n",
      "Epoch 4: Loss = 0.7360615730285645\n",
      "Epoch 5: Loss = 0.6455391049385071\n",
      "Epoch 6: Loss = 0.5686070322990417\n",
      "Epoch 7: Loss = 0.5029894113540649\n",
      "Epoch 8: Loss = 0.4471339285373688\n",
      "Epoch 9: Loss = 0.39898037910461426\n",
      "Epoch 10: Loss = 0.3572620749473572\n",
      "Epoch 11: Loss = 0.3208051323890686\n",
      "Epoch 12: Loss = 0.2894327938556671\n",
      "Epoch 13: Loss = 0.2623589336872101\n",
      "Epoch 14: Loss = 0.23931550979614258\n",
      "Epoch 15: Loss = 0.2199365794658661\n",
      "Epoch 16: Loss = 0.2037183940410614\n",
      "Epoch 17: Loss = 0.1905381679534912\n",
      "Epoch 18: Loss = 0.17951081693172455\n",
      "Epoch 19: Loss = 0.170089989900589\n",
      "Epoch 20: Loss = 0.16206490993499756\n",
      "Epoch 21: Loss = 0.15493540465831757\n",
      "Epoch 22: Loss = 0.14863745868206024\n",
      "Epoch 23: Loss = 0.14282920956611633\n",
      "Epoch 24: Loss = 0.13739457726478577\n",
      "Epoch 25: Loss = 0.13230040669441223\n",
      "Epoch 26: Loss = 0.12755826115608215\n",
      "Epoch 27: Loss = 0.12328652292490005\n",
      "Epoch 28: Loss = 0.11930672079324722\n",
      "Epoch 29: Loss = 0.11562363803386688\n",
      "Epoch 30: Loss = 0.11213034391403198\n",
      "Epoch 31: Loss = 0.1087103858590126\n",
      "Epoch 32: Loss = 0.10533447563648224\n",
      "Epoch 33: Loss = 0.10200925916433334\n",
      "Epoch 34: Loss = 0.09873751550912857\n",
      "Epoch 35: Loss = 0.09557235240936279\n",
      "Epoch 36: Loss = 0.09249666333198547\n",
      "Epoch 37: Loss = 0.08948028832674026\n",
      "Epoch 38: Loss = 0.08652396500110626\n",
      "Epoch 39: Loss = 0.08362346142530441\n",
      "Epoch 40: Loss = 0.08079200237989426\n",
      "Epoch 41: Loss = 0.07800948619842529\n",
      "Epoch 42: Loss = 0.0752841979265213\n",
      "Epoch 43: Loss = 0.07267679274082184\n",
      "Epoch 44: Loss = 0.07026588916778564\n",
      "Epoch 45: Loss = 0.06794575601816177\n",
      "Epoch 46: Loss = 0.06576672941446304\n",
      "Epoch 47: Loss = 0.06362644582986832\n",
      "Epoch 48: Loss = 0.061524879187345505\n",
      "Epoch 49: Loss = 0.05943996459245682\n",
      "Epoch 50: Loss = 0.05738940089941025\n",
      "Epoch 51: Loss = 0.05540505796670914\n",
      "Epoch 52: Loss = 0.053539734333753586\n",
      "Epoch 53: Loss = 0.051720213145017624\n",
      "Epoch 54: Loss = 0.049935776740312576\n",
      "Epoch 55: Loss = 0.04819392040371895\n",
      "Epoch 56: Loss = 0.04652085155248642\n",
      "Epoch 57: Loss = 0.044909026473760605\n",
      "Epoch 58: Loss = 0.04337260499596596\n",
      "Epoch 59: Loss = 0.04193137213587761\n",
      "Epoch 60: Loss = 0.04052334278821945\n",
      "Epoch 61: Loss = 0.03914010524749756\n",
      "Epoch 62: Loss = 0.03781769797205925\n",
      "Epoch 63: Loss = 0.036550380289554596\n",
      "Epoch 64: Loss = 0.035324424505233765\n",
      "Epoch 65: Loss = 0.03414897248148918\n",
      "Epoch 66: Loss = 0.03302114084362984\n",
      "Epoch 67: Loss = 0.0319349467754364\n",
      "Epoch 68: Loss = 0.03088177740573883\n",
      "Epoch 69: Loss = 0.029896726831793785\n",
      "Epoch 70: Loss = 0.028952226042747498\n",
      "Epoch 71: Loss = 0.02803308703005314\n",
      "Epoch 72: Loss = 0.02715972065925598\n",
      "Epoch 73: Loss = 0.026308516040444374\n",
      "Epoch 74: Loss = 0.025481577962636948\n",
      "Epoch 75: Loss = 0.024702267721295357\n",
      "Epoch 76: Loss = 0.023964952677488327\n",
      "Epoch 77: Loss = 0.02326720952987671\n",
      "Epoch 78: Loss = 0.022588282823562622\n",
      "Epoch 79: Loss = 0.021933075040578842\n",
      "Epoch 80: Loss = 0.021298164501786232\n",
      "Epoch 81: Loss = 0.02068629302084446\n",
      "Epoch 82: Loss = 0.020095493644475937\n",
      "Epoch 83: Loss = 0.019528713077306747\n",
      "Epoch 84: Loss = 0.01898745819926262\n",
      "Epoch 85: Loss = 0.01847343146800995\n",
      "Epoch 86: Loss = 0.01796945370733738\n",
      "Epoch 87: Loss = 0.01748313382267952\n",
      "Epoch 88: Loss = 0.01701902225613594\n",
      "Epoch 89: Loss = 0.01658136583864689\n",
      "Epoch 90: Loss = 0.016156282275915146\n",
      "Epoch 91: Loss = 0.015747442841529846\n",
      "Epoch 92: Loss = 0.015351328067481518\n",
      "Epoch 93: Loss = 0.014970019459724426\n",
      "Epoch 94: Loss = 0.014600502327084541\n",
      "Epoch 95: Loss = 0.01424316130578518\n",
      "Epoch 96: Loss = 0.013896545395255089\n",
      "Epoch 97: Loss = 0.013567149639129639\n",
      "Epoch 98: Loss = 0.013247549533843994\n",
      "Epoch 99: Loss = 0.012933632358908653\n",
      "Epoch 100: Loss = 0.012632283382117748\n",
      "Epoch 101: Loss = 0.012343807145953178\n",
      "Epoch 102: Loss = 0.012064190581440926\n",
      "Epoch 103: Loss = 0.011791271157562733\n",
      "Epoch 104: Loss = 0.011526047252118587\n",
      "Epoch 105: Loss = 0.011268502101302147\n",
      "Epoch 106: Loss = 0.011017175391316414\n",
      "Epoch 107: Loss = 0.010776689276099205\n",
      "Epoch 108: Loss = 0.010544771328568459\n",
      "Epoch 109: Loss = 0.010317714884877205\n",
      "Epoch 110: Loss = 0.0100978659465909\n",
      "Epoch 111: Loss = 0.009883319959044456\n",
      "Epoch 112: Loss = 0.009679244831204414\n",
      "Epoch 113: Loss = 0.009480319917201996\n",
      "Epoch 114: Loss = 0.009284397587180138\n",
      "Epoch 115: Loss = 0.009096425957977772\n",
      "Epoch 116: Loss = 0.008916324004530907\n",
      "Epoch 117: Loss = 0.008740102872252464\n",
      "Epoch 118: Loss = 0.00856845360249281\n",
      "Epoch 119: Loss = 0.008403174579143524\n",
      "Epoch 120: Loss = 0.008242509327828884\n",
      "Epoch 121: Loss = 0.008086826652288437\n",
      "Epoch 122: Loss = 0.007934967055916786\n",
      "Epoch 123: Loss = 0.0077874078415334225\n",
      "Epoch 124: Loss = 0.0076427520252764225\n",
      "Epoch 125: Loss = 0.00750275794416666\n",
      "Epoch 126: Loss = 0.007367545273154974\n",
      "Epoch 127: Loss = 0.007235138677060604\n",
      "Epoch 128: Loss = 0.007106425706297159\n",
      "Epoch 129: Loss = 0.006980757229030132\n",
      "Epoch 130: Loss = 0.006858537904918194\n",
      "Epoch 131: Loss = 0.00674071442335844\n",
      "Epoch 132: Loss = 0.006625568959861994\n",
      "Epoch 133: Loss = 0.006512696389108896\n",
      "Epoch 134: Loss = 0.006401897873729467\n",
      "Epoch 135: Loss = 0.006296281702816486\n",
      "Epoch 136: Loss = 0.006192408502101898\n",
      "Epoch 137: Loss = 0.006090219132602215\n",
      "Epoch 138: Loss = 0.005990212317556143\n",
      "Epoch 139: Loss = 0.005894037429243326\n",
      "Epoch 140: Loss = 0.005800317972898483\n",
      "Epoch 141: Loss = 0.005708201788365841\n",
      "Epoch 142: Loss = 0.005619889125227928\n",
      "Epoch 143: Loss = 0.005532106384634972\n",
      "Epoch 144: Loss = 0.005445691291242838\n",
      "Epoch 145: Loss = 0.005362045951187611\n",
      "Epoch 146: Loss = 0.005280540324747562\n",
      "Epoch 147: Loss = 0.005202000495046377\n",
      "Epoch 148: Loss = 0.005125041585415602\n",
      "Epoch 149: Loss = 0.005048877093940973\n",
      "Epoch 150: Loss = 0.0049736229702830315\n",
      "Epoch 151: Loss = 0.004901357926428318\n",
      "Epoch 152: Loss = 0.004831226542592049\n",
      "Epoch 153: Loss = 0.004762229509651661\n",
      "Epoch 154: Loss = 0.004694380331784487\n",
      "Epoch 155: Loss = 0.004628336988389492\n",
      "Epoch 156: Loss = 0.004563069902360439\n",
      "Epoch 157: Loss = 0.0044994475319981575\n",
      "Epoch 158: Loss = 0.0044378722086548805\n",
      "Epoch 159: Loss = 0.004378052428364754\n",
      "Epoch 160: Loss = 0.004321718122810125\n",
      "Epoch 161: Loss = 0.004265996627509594\n",
      "Epoch 162: Loss = 0.0042109242640435696\n",
      "Epoch 163: Loss = 0.0041572460904717445\n",
      "Epoch 164: Loss = 0.004104623105376959\n",
      "Epoch 165: Loss = 0.004052524920552969\n",
      "Epoch 166: Loss = 0.0040012747049331665\n",
      "Epoch 167: Loss = 0.003951179329305887\n",
      "Epoch 168: Loss = 0.0039019633550196886\n",
      "Epoch 169: Loss = 0.0038539855740964413\n",
      "Epoch 170: Loss = 0.0038072136230766773\n",
      "Epoch 171: Loss = 0.00376119208522141\n",
      "Epoch 172: Loss = 0.0037166171241551638\n",
      "Epoch 173: Loss = 0.0036724540404975414\n",
      "Epoch 174: Loss = 0.003628582926467061\n",
      "Epoch 175: Loss = 0.003585872007533908\n",
      "Epoch 176: Loss = 0.003543925704434514\n",
      "Epoch 177: Loss = 0.003502639476209879\n",
      "Epoch 178: Loss = 0.0034622810781002045\n",
      "Epoch 179: Loss = 0.0034224987030029297\n",
      "Epoch 180: Loss = 0.003383681643754244\n",
      "Epoch 181: Loss = 0.0033453702926635742\n",
      "Epoch 182: Loss = 0.003307902719825506\n",
      "Epoch 183: Loss = 0.0032708451617509127\n",
      "Epoch 184: Loss = 0.0032346267253160477\n",
      "Epoch 185: Loss = 0.0031989545095711946\n",
      "Epoch 186: Loss = 0.003164128866046667\n",
      "Epoch 187: Loss = 0.0031297500245273113\n",
      "Epoch 188: Loss = 0.0030957653652876616\n",
      "Epoch 189: Loss = 0.0030624507926404476\n",
      "Epoch 190: Loss = 0.0030298768542706966\n",
      "Epoch 191: Loss = 0.002997675910592079\n",
      "Epoch 192: Loss = 0.002966084750369191\n",
      "Epoch 193: Loss = 0.0029350961558520794\n",
      "Epoch 194: Loss = 0.0029044426046311855\n",
      "Epoch 195: Loss = 0.0028743648435920477\n",
      "Epoch 196: Loss = 0.002844973001629114\n",
      "Epoch 197: Loss = 0.0028157131746411324\n",
      "Epoch 198: Loss = 0.0027868954930454493\n",
      "Epoch 199: Loss = 0.0027586196083575487\n",
      "Epoch 200: Loss = 0.0027308412827551365\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(16, 32)\n",
    "        self.conv2 = GCNConv(32, 3)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = GCN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "for epoch in range(200):\n",
    "    loss = train()\n",
    "    print(f'Epoch {epoch+1}: Loss = {loss.item()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 77/77 [00:00<00:00, 231.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected communities: [0 0 0 3 2 4 0 4 1 4 3 3 0 1 4 0 4 1 3 3 2 1 1 1 3 1 0 4 2 0 3 1 2 0 0 4 4\n",
      " 2 3 0 3 0 3 3 4 3 0 1 2 3 0 0 3 3 0 2 3 3 0 3 1 3 3 3 3 3 3 0 0 3 0 1 0 2\n",
      " 1 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kctco\\anaconda3\\envs\\gis\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "data = pd.read_csv('all_collected_data.csv', encoding=\"EUC-KR\")\n",
    "edges = data[[\"출발 행정동 코드\", \"도착 행정동 코드\", \"이동인구(합)\"]]\n",
    "\n",
    "G = nx.Graph()\n",
    "for index, row in edges.iterrows():\n",
    "    if pd.notna(row[\"이동인구(합)\"]):\n",
    "        G.add_edge(\n",
    "            row[\"출발 행정동 코드\"], row[\"도착 행정동 코드\"], weight=row[\"이동인구(합)\"]\n",
    "        )\n",
    "\n",
    "node2vec = Node2Vec(G, dimensions=64, walk_length=30, num_walks=200, workers=4)\n",
    "\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "\n",
    "node_embeddings = model.wv.vectors\n",
    "\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "communities = kmeans.fit_predict(node_embeddings)\n",
    "\n",
    "print(\"Detected communities:\", communities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kctco\\AppData\\Local\\Temp\\ipykernel_170536\\3262077750.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  node_embeddings = torch.tensor(node_embeddings, dtype=torch.float)  # node2vec의 결과\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 3, 2, 4, 0, 4, 1, 4, 3, 3, 0, 1, 4, 0, 4, 1, 3, 3, 2, 1, 1, 1,\n",
      "        3, 1, 0, 4, 2, 0, 3, 1, 2, 0, 0, 4, 4, 2, 3, 0, 3, 0, 3, 3, 4, 3, 0, 1,\n",
      "        2, 3, 0, 0, 3, 3, 0, 2, 3, 3, 0, 3, 1, 3, 3, 3, 3, 3, 3, 0, 0, 3, 0, 1,\n",
      "        0, 2, 1, 2, 3])\n",
      "Epoch 1: Loss = 1.614825963973999\n",
      "Epoch 101: Loss = 1.4794566631317139\n",
      "Accuracy: 0.3377\n",
      "Community 3: Nodes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import from_networkx\n",
    "import pandas as pd\n",
    "\n",
    "data_df = pd.read_csv('all_collected_data.csv', encoding=\"EUC-KR\")\n",
    "edges = data_df[[\"출발 행정동 코드\", \"도착 행정동 코드\", \"이동인구(합)\"]]\n",
    "\n",
    "G = nx.Graph()\n",
    "for index, row in edges.iterrows():\n",
    "    if pd.notna(row[\"이동인구(합)\"]):\n",
    "        G.add_edge(\n",
    "            int(row[\"출발 행정동 코드\"]), int(row[\"도착 행정동 코드\"]), weight=float(row[\"이동인구(합)\"])\n",
    "        )\n",
    "\n",
    "data = from_networkx(G)\n",
    "\n",
    "node_embeddings = torch.tensor(node_embeddings, dtype=torch.float) \n",
    "data.x = node_embeddings  \n",
    "data.y = torch.tensor(communities, dtype=torch.long)\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(data.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, max(data.y)+1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(hidden_channels=64).to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out, data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "for epoch in range(200):\n",
    "    loss = train()\n",
    "    if epoch % 100 == 0 :\n",
    "        print(f'Epoch {epoch+1}: Loss = {loss}')\n",
    "\n",
    "model.eval()\n",
    "_, pred = model(data.x, data.edge_index).max(dim=1)\n",
    "correct = (pred == data.y).sum().item()\n",
    "accuracy = correct / data.y.size(0)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "model.eval()\n",
    "_, pred = model(data.x, data.edge_index).max(dim=1)\n",
    "\n",
    "community_nodes = defaultdict(list)\n",
    "for node_index, community in enumerate(pred.tolist()):\n",
    "    community_nodes[community].append(node_index)\n",
    "\n",
    "for community, nodes in community_nodes.items():\n",
    "    print(f'Community {community}: Nodes {nodes}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected communities: [2 3 3 3 2 3 3 9 2 3 9 2 3 2 3 2 2 3 3 9 3 2 3 2 2 6 0 7 8 6 6 8 6 7 6 1 6\n",
      " 7 5 6 7 4 7 5 7 6 5 8 7 7 0 7 1 7 5 5 5 0 7 4 1 7 6 6 0 5 0 6 1 0 8 6 0 0\n",
      " 7 0 7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kctco\\anaconda3\\envs\\gis\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "data_df = pd.read_csv('all_collected_data.csv', encoding=\"EUC-KR\")\n",
    "edges = data_df[[\"출발 행정동 코드\", \"도착 행정동 코드\", \"이동인구(합)\"]]\n",
    "\n",
    "G = nx.Graph()\n",
    "for index, row in edges.iterrows():\n",
    "    if pd.notna(row[\"이동인구(합)\"]):\n",
    "        G.add_edge(\n",
    "            int(row[\"출발 행정동 코드\"]), int(row[\"도착 행정동 코드\"]), weight=float(row[\"이동인구(합)\"])\n",
    "        )\n",
    "\n",
    "def perform_random_walks(graph, num_walks, walk_length):\n",
    "    walks = []\n",
    "    for _ in range(num_walks):\n",
    "        for starting_node in graph.nodes():\n",
    "            walk = [starting_node]\n",
    "            while len(walk) < walk_length:\n",
    "                current_node = walk[-1]\n",
    "                neighbors = list(graph.neighbors(current_node))\n",
    "                if not neighbors:\n",
    "                    break\n",
    "                next_node = random.choice(neighbors)\n",
    "                walk.append(next_node)\n",
    "            walks.append(walk)\n",
    "    return walks\n",
    "\n",
    "\n",
    "# DeepWalk 실행\n",
    "walks = perform_random_walks(G, num_walks=10, walk_length=80)\n",
    "walks = [[str(node) for node in walk] for walk in walks]\n",
    "\n",
    "model = Word2Vec(sentences=walks, vector_size=64, window=10, min_count=1, sg=1, workers=4, epochs=10)\n",
    "\n",
    "node_embeddings = np.array([model.wv[str(node)] for node in G.nodes()])\n",
    "\n",
    "kmeans = KMeans(n_clusters=10)\n",
    "communities = kmeans.fit_predict(node_embeddings)\n",
    "\n",
    "print(\"Detected communities:\", communities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected communities: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 3 4 3 2 0 0 0 3 2 0 4\n",
      " 2 3 2 2 2 3 0 2 3 3 0 2 0 4 2 2 0 4 3 0 4 0 3 3 3 2 0 2 3 4 2 4 0 4 4 3 3\n",
      " 4 3 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kctco\\anaconda3\\envs\\gis\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def perform_random_walks(graph, num_walks, walk_length):\n",
    "    walks = []\n",
    "    for _ in range(num_walks):\n",
    "        for starting_node in graph.nodes():\n",
    "            walk = [starting_node]\n",
    "            while len(walk) < walk_length:\n",
    "                current_node = walk[-1]\n",
    "                neighbors = list(graph.neighbors(current_node))\n",
    "                if not neighbors:\n",
    "                    break\n",
    "                next_node = random.choice(neighbors)\n",
    "                walk.append(next_node)\n",
    "            walks.append(walk)\n",
    "    return walks\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "data_df = pd.read_csv('all_collected_data.csv', encoding=\"EUC-KR\")\n",
    "edges = data_df[[\"출발 행정동 코드\", \"도착 행정동 코드\", \"이동인구(합)\"]]\n",
    "\n",
    "G = nx.Graph()\n",
    "for index, row in edges.iterrows():\n",
    "    if pd.notna(row[\"이동인구(합)\"]):\n",
    "        G.add_edge(\n",
    "            int(row[\"출발 행정동 코드\"]), int(row[\"도착 행정동 코드\"]), weight=float(row[\"이동인구(합)\"])\n",
    "        )\n",
    "\n",
    "walks = perform_random_walks(G, num_walks=10, walk_length=80)\n",
    "walks = [[str(node) for node in walk] for walk in walks]\n",
    "\n",
    "model = Word2Vec(sentences=walks, vector_size=64, window=10, min_count=1, sg=1, workers=4, epochs=10)\n",
    "node_embeddings = np.array([model.wv[str(node)] for node in G.nodes()])\n",
    "\n",
    "kmeans = KMeans(n_clusters=10)\n",
    "communities = kmeans.fit_predict(node_embeddings)\n",
    "\n",
    "print(\"Detected communities:\", communities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community 3: [11010, 11030, 11060, 11100, 11120, 11170, 11180, 11190, 11200, 11220]\n",
      "Community 8: [11020, 11040, 11080, 11090, 11110, 11130, 11160, 11230, 11250]\n",
      "Community 1: [11050, 11070, 11140, 11150, 11210, 11240]\n",
      "Community 2: [23010, 23080, 31092, 31101, 31110, 31120, 31260, 31280]\n",
      "Community 4: [23020, 23060, 31011, 31012, 31023, 31191, 31240, 31270, 31370]\n",
      "Community 0: [23030, 23310, 31042, 31080, 31192]\n",
      "Community 9: [23040, 23050, 23070, 31014, 31030, 31070, 31103, 31104, 31150, 31160, 31170, 31180, 31210, 31220, 31230]\n",
      "Community 7: [23320, 31022, 31050, 31091, 31140, 31193, 31250, 31350, 31380]\n",
      "Community 6: [31013, 31130, 31200]\n",
      "Community 5: [31021, 31041, 31060]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kctco\\anaconda3\\envs\\gis\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def perform_random_walks(graph, num_walks, walk_length):\n",
    "    walks = []\n",
    "    for _ in range(num_walks):\n",
    "        for starting_node in graph.nodes():\n",
    "            walk = [starting_node]\n",
    "            while len(walk) < walk_length:\n",
    "                current_node = walk[-1]\n",
    "                neighbors = list(graph.neighbors(current_node))\n",
    "                if not neighbors:\n",
    "                    break\n",
    "                next_node = random.choice(neighbors)\n",
    "                walk.append(next_node)\n",
    "            walks.append(walk)\n",
    "    return walks\n",
    "\n",
    "data_df = pd.read_csv('all_collected_data.csv', encoding=\"EUC-KR\")\n",
    "edges = data_df[[\"출발 행정동 코드\", \"도착 행정동 코드\", \"이동인구(합)\"]]\n",
    "\n",
    "G = nx.Graph()\n",
    "for index, row in edges.iterrows():\n",
    "    if pd.notna(row[\"이동인구(합)\"]):\n",
    "        G.add_edge(\n",
    "            int(row[\"출발 행정동 코드\"]), int(row[\"도착 행정동 코드\"]), weight=float(row[\"이동인구(합)\"])\n",
    "        )\n",
    "\n",
    "walks = perform_random_walks(G, num_walks=10, walk_length=80)\n",
    "walks = [[str(node) for node in walk] for walk in walks]\n",
    "\n",
    "model = Word2Vec(sentences=walks, vector_size=64, window=10, min_count=1, sg=1, workers=4, epochs=10)\n",
    "node_embeddings = np.array([model.wv[str(node)] for node in G.nodes()])\n",
    "\n",
    "kmeans = KMeans(n_clusters=10)\n",
    "communities = kmeans.fit_predict(node_embeddings)\n",
    "\n",
    "community_dict = {}\n",
    "for node, community in zip(G.nodes(), communities):\n",
    "    if community not in community_dict:\n",
    "        community_dict[community] = []\n",
    "    community_dict[community].append(node)\n",
    "\n",
    "for community, nodes in community_dict.items():\n",
    "    print(f\"Community {community}: {nodes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "konlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
